{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import heapq\n",
    "\n",
    "# Node Class represents a state in the search tree.\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        self.state = state  # The current position of the agent in the grid.\n",
    "        self.parent = parent  # The node in the search tree that generated this node.\n",
    "        self.action = action  # The action taken to get to this state.\n",
    "        self.path_cost = path_cost  # Cost from the start node to this node.\n",
    "\n",
    "    # Comparison operator for priority queue.\n",
    "    def __lt__(self, other):\n",
    "        return self.path_cost < other.path_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a star search we need to define a priority queue and heuristic. here we have taken the manhattan distance as the heuristic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self.elements = []\n",
    "\n",
    "    def empty(self):\n",
    "        return len(self.elements) == 0\n",
    "\n",
    "    def put(self, item, priority):\n",
    "        heapq.heappush(self.elements, (priority, item))\n",
    "\n",
    "    def get(self):\n",
    "        return heapq.heappop(self.elements)[1]\n",
    "def heuristic(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points a and b.\n",
    "\n",
    "    Parameters:\n",
    "    - a: Tuple representing the x and y coordinates of point a (e.g., (x1, y1))\n",
    "    - b: Tuple representing the x and y coordinates of point b (e.g., (x2, y2))\n",
    "\n",
    "    Returns:\n",
    "    - The Manhattan distance between points a and b.\n",
    "    \"\"\"\n",
    "    (x1, y1) = a\n",
    "    (x2, y2) = b\n",
    "    return abs(x1 - x2) + abs(y1 - y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a class Environment that generates a 10x10 grid. Dynamically\n",
    "place obstacles, a start position, and an end position within the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Class represents the grid and handles state transitions.\n",
    "class Environment:\n",
    "    def __init__(self, grid, start, goal):\n",
    "        self.grid = grid  # The grid layout where 1 represents an obstacle and 0 is free space.\n",
    "        self.initial = start  # Starting position of the agent.\n",
    "        self.goal = goal  # Goal position the agent aims to reach.\n",
    "\n",
    "    # Returns the possible actions from a given state.\n",
    "    def actions(self, state):\n",
    "        possible_actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "        x, y = state\n",
    "\n",
    "        # Remove impossible actions based on grid boundaries and obstacles.\n",
    "        if x == 0 or self.grid[x - 1][y] == 1:\n",
    "            possible_actions.remove('UP')\n",
    "        if x == len(self.grid) - 1 or self.grid[x + 1][y] == 1:\n",
    "            possible_actions.remove('DOWN')\n",
    "        if y == 0 or self.grid[x][y - 1] == 1:\n",
    "            possible_actions.remove('LEFT')\n",
    "        if y == len(self.grid[0]) - 1 or self.grid[x][y + 1] == 1:\n",
    "            possible_actions.remove('RIGHT')\n",
    "\n",
    "        return possible_actions\n",
    "\n",
    "    # Returns the state resulting from taking a given action at a given state.\n",
    "    def result(self, state, action):\n",
    "        x, y = state\n",
    "        if action == 'UP':\n",
    "            return (x - 1, y)\n",
    "        if action == 'DOWN':\n",
    "            return (x + 1, y)\n",
    "        if action == 'LEFT':\n",
    "            return (x, y - 1)\n",
    "        if action == 'RIGHT':\n",
    "            return (x, y + 1)\n",
    "\n",
    "    # Checks if the goal has been reached.\n",
    "    def is_goal(self, state):\n",
    "        return state == self.goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Robot\n",
    "• Implement a class Agent with movement capabilities and tracking of its\n",
    "current position. Include methods to manage the robot's energy levels and\n",
    "battery status, incorporating task optimization and safety for efficient and safe\n",
    "navigation.\n",
    "• Battery Management: The robot starts with a battery level of 100%. For each\n",
    "move from one block to another, the battery level decreases by 10%. If the\n",
    "battery level reaches 0%, the robot must recharge to 100% before continuing.\n",
    "\n",
    "2. Simulation\n",
    "• Simulate the robot's movement through the 10x10 grid with randomly placed\n",
    "obstacles, accounting for energy consumption and managing energy levels to\n",
    "complete tasks.\n",
    "3. Pathfinding Algorithms\n",
    "• Students are required to implement two pathfinding algorithms: Uniform Cost\n",
    "Search (UCS) and A* (A Star). Evaluate these algorithms based on the number\n",
    "of times the robot needs to recharge its battery while traversing the path to the\n",
    "goal. This will determine the best algorithm for this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Class uses BFS to find a path from start to goal.\n",
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env  # The environment in which the agent operates.\n",
    "\n",
    "    # Performs BFS search to find a path from the initial state to the goal.\n",
    "    def uniform_cost_search(self):\n",
    "        frontier = PriorityQueue()  # Priority queue for UCS.\n",
    "        frontier.put(Node(self.env.initial, path_cost=0), 0)\n",
    "        came_from = {self.env.initial: None}\n",
    "        cost_so_far = {self.env.initial: 0}\n",
    "\n",
    "        while not frontier.empty():\n",
    "            current_node = frontier.get()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity; adjust if varying costs.\n",
    "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
    "                    cost_so_far[new_state] = new_cost\n",
    "                    priority = new_cost\n",
    "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
    "                    came_from[new_state] = current_node.state\n",
    "\n",
    "        return []\n",
    "    def a_star_search(self):\n",
    "        # The start node is created with a path cost of 0.\n",
    "        start_node = Node(self.env.initial, path_cost=0)\n",
    "        frontier = PriorityQueue()\n",
    "        frontier.put(start_node, 0)  # Priority is f-cost, initially the heuristic cost from start to goal\n",
    "        came_from = {self.env.initial: None}  # Tracks the best path to a node\n",
    "        cost_so_far = {self.env.initial: 0}  # Tracks the g-cost (cost so far to reach a node)\n",
    "\n",
    "        while not frontier.empty():\n",
    "            current_node = frontier.get()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity\n",
    "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
    "                    cost_so_far[new_state] = new_cost\n",
    "                    priority = new_cost + heuristic(new_state, self.env.goal)  # f-cost = g-cost + h-cost\n",
    "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
    "                    came_from[new_state] = current_node.state\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Reconstructs the path from start to goal by following the came_from links.\n",
    "    def reconstruct_path(self, came_from, current):\n",
    "        path = []\n",
    "        while current in came_from:\n",
    "            path.append(current)\n",
    "            current = came_from[current]\n",
    "        path.append(self.env.initial)  # Start is not included in the came_from map.\n",
    "        path.reverse()  # Reverse to get the path from start to goal.\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Function plots the grid and the found path.\n",
    "def visualize_grid_and_path(grid, path):\n",
    "    grid_array = np.array(grid)  # Convert grid to numpy array for easy plotting.\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(grid_array, cmap='Greys', alpha=0.3)  # Grid background.\n",
    "    start = path[0]\n",
    "    goal = path[-1]\n",
    "    ax.plot(start[1], start[0], 'bs', markersize=10)  # Start position in blue.\n",
    "    ax.plot(goal[1], goal[0], 'gs', markersize=10)  # Goal position in green.\n",
    "    xs, ys = zip(*path)  # Extract X and Y coordinates of the path.\n",
    "    ax.plot(ys, xs, 'r-', linewidth=2)  # Plot the path in red.\n",
    "    ax.set_xticks(np.arange(-.5, len(grid[0]), 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, len(grid), 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"b\", linestyle='-', linewidth=1)\n",
    "    ax.tick_params(which=\"minor\", size=0)\n",
    "    ax.tick_params(which=\"major\", bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "driver code. \n",
    "\n",
    "<h3>output serial</h3>\n",
    "<hr>\n",
    "1st --> UFS<br>\n",
    "2nd --> A Star "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution Path bfs: [(0, 0), (0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (5, 1), (5, 2), (6, 2), (7, 2), (7, 3), (7, 4), (8, 4), (8, 5), (8, 6), (8, 7), (9, 7), (9, 8), (9, 9)]\n",
      "Solution path A star: [(0, 0), (0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4), (4, 5), (4, 6), (5, 6), (6, 6), (7, 6), (8, 6), (8, 7), (9, 7), (9, 8), (9, 9)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the grid, start position, and goal position\n",
    "def generate_random_grid(size, obstacle_probability):\n",
    "    return np.random.choice([0, 1], size=(size, size), p=[1-obstacle_probability, obstacle_probability])\n",
    "grid_size = 10\n",
    "obstacle_probability = 0.2 \n",
    "grid = generate_random_grid(grid_size, obstacle_probability)\n",
    "start = (0, 0)\n",
    "goal = (grid_size - 1, grid_size - 1)\n",
    "\n",
    "grid[start] = 0\n",
    "grid[goal] = 0\n",
    "# Create the environment and agent\n",
    "environment = Environment(grid, start, goal)\n",
    "agent = Agent(environment)\n",
    "\n",
    "# Solve the problem with BFS\n",
    "solution_path = agent.uniform_cost_search()\n",
    "solution_path_1 = agent.a_star_search()\n",
    "\n",
    "print(\"Solution Path bfs:\", solution_path)\n",
    "print(\"Solution path A star:\", solution_path_1)\n",
    "\n",
    "# Visualize the solution\n",
    "visualize_grid_and_path(grid, solution_path)\n",
    "visualize_grid_and_path(grid, solution_path_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
