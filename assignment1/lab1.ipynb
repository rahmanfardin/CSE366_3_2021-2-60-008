{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import heapq\n",
    "\n",
    "# Node Class represents a state in the search tree.\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        self.state = state  # The current position of the agent in the grid.\n",
    "        self.parent = parent  # The node in the search tree that generated this node.\n",
    "        self.action = action  # The action taken to get to this state.\n",
    "        self.path_cost = path_cost  # Cost from the start node to this node.\n",
    "\n",
    "    # Comparison operator for priority queue.\n",
    "    def __lt__(self, other):\n",
    "        return self.path_cost < other.path_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a star search we need to define a priority queue and heuristic. here we have taken the manhattan distance as the heuristic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self.elements = []\n",
    "\n",
    "    def empty(self):\n",
    "        return len(self.elements) == 0\n",
    "\n",
    "    def put(self, item, priority):\n",
    "        heapq.heappush(self.elements, (priority, item))\n",
    "\n",
    "    def get(self):\n",
    "        return heapq.heappop(self.elements)[1]\n",
    "def heuristic(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points a and b.\n",
    "\n",
    "    Parameters:\n",
    "    - a: Tuple representing the x and y coordinates of point a (e.g., (x1, y1))\n",
    "    - b: Tuple representing the x and y coordinates of point b (e.g., (x2, y2))\n",
    "\n",
    "    Returns:\n",
    "    - The Manhattan distance between points a and b.\n",
    "    \"\"\"\n",
    "    (x1, y1) = a\n",
    "    (x2, y2) = b\n",
    "    return abs(x1 - x2) + abs(y1 - y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a class Environment that generates a 10x10 grid. Dynamically\n",
    "place obstacles, a start position, and an end position within the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Class represents the grid and handles state transitions.\n",
    "class Environment:\n",
    "    def __init__(self, grid, start, goal):\n",
    "        self.grid = grid  # The grid layout where 1 represents an obstacle and 0 is free space.\n",
    "        self.initial = start  # Starting position of the agent.\n",
    "        self.goal = goal  # Goal position the agent aims to reach.\n",
    "\n",
    "    # Returns the possible actions from a given state.\n",
    "    def actions(self, state):\n",
    "        possible_actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "        x, y = state\n",
    "\n",
    "        # Remove impossible actions based on grid boundaries and obstacles.\n",
    "        if x == 0 or self.grid[x - 1][y] == 1:\n",
    "            possible_actions.remove('UP')\n",
    "        if x == len(self.grid) - 1 or self.grid[x + 1][y] == 1:\n",
    "            possible_actions.remove('DOWN')\n",
    "        if y == 0 or self.grid[x][y - 1] == 1:\n",
    "            possible_actions.remove('LEFT')\n",
    "        if y == len(self.grid[0]) - 1 or self.grid[x][y + 1] == 1:\n",
    "            possible_actions.remove('RIGHT')\n",
    "\n",
    "        return possible_actions\n",
    "\n",
    "    # Returns the state resulting from taking a given action at a given state.\n",
    "    def result(self, state, action):\n",
    "        x, y = state\n",
    "        if action == 'UP':\n",
    "            return (x - 1, y)\n",
    "        if action == 'DOWN':\n",
    "            return (x + 1, y)\n",
    "        if action == 'LEFT':\n",
    "            return (x, y - 1)\n",
    "        if action == 'RIGHT':\n",
    "            return (x, y + 1)\n",
    "\n",
    "    # Checks if the goal has been reached.\n",
    "    def is_goal(self, state):\n",
    "        return state == self.goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Robot\n",
    "• Implement a class Agent with movement capabilities and tracking of its\n",
    "current position. Include methods to manage the robot's energy levels and\n",
    "battery status, incorporating task optimization and safety for efficient and safe\n",
    "navigation.\n",
    "• Battery Management: The robot starts with a battery level of 100%. For each\n",
    "move from one block to another, the battery level decreases by 10%. If the\n",
    "battery level reaches 0%, the robot must recharge to 100% before continuing.\n",
    "\n",
    "2. Simulation\n",
    "• Simulate the robot's movement through the 10x10 grid with randomly placed\n",
    "obstacles, accounting for energy consumption and managing energy levels to\n",
    "complete tasks.\n",
    "3. Pathfinding Algorithms\n",
    "• Students are required to implement two pathfinding algorithms: Uniform Cost\n",
    "Search (UCS) and A* (A Star). Evaluate these algorithms based on the number\n",
    "of times the robot needs to recharge its battery while traversing the path to the\n",
    "goal. This will determine the best algorithm for this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env  # The environment in which the agent operates.\n",
    "        self.battery = 100 # int((np.random.randint(100))/10)*10 Initial battery level\n",
    "\n",
    "    #battery section\n",
    "    def recharge(self):\n",
    "        self.battery = 100\n",
    "    \n",
    "    def current_charge(self):\n",
    "        return self.battery\n",
    "    \n",
    "    # Performs UCS search to find a path from the initial state to the goal.\n",
    "    def uniform_cost_search(self):\n",
    "        frontier = PriorityQueue()  # Priority queue for UCS.\n",
    "        frontier.put(Node(self.env.initial, path_cost=0), 0)\n",
    "        came_from = {self.env.initial: None}\n",
    "        cost_so_far = {self.env.initial: 0}\n",
    "\n",
    "        while not frontier.empty():\n",
    "            current_node = frontier.get()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity; adjust if varying costs.\n",
    "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
    "                    cost_so_far[new_state] = new_cost\n",
    "                    priority = new_cost\n",
    "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
    "                    came_from[new_state] = current_node.state\n",
    "        return []\n",
    "    \n",
    "    # This is a_star_search \n",
    "    def a_star_search(self):\n",
    "        #self.recharge()\n",
    "        # The start node is created with a path cost of 0.\n",
    "        start_node = Node(self.env.initial, path_cost=0)\n",
    "        frontier = PriorityQueue()\n",
    "        frontier.put(start_node, 0)  # Priority is f-cost, initially the heuristic cost from start to goal\n",
    "        came_from = {self.env.initial: None}  # Tracks the best path to a node\n",
    "        cost_so_far = {self.env.initial: 0}  # Tracks the g-cost (cost so far to reach a node)\n",
    "\n",
    "        while not frontier.empty():\n",
    "            current_node = frontier.get()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity\n",
    "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
    "                    cost_so_far[new_state] = new_cost\n",
    "                    priority = new_cost + heuristic(new_state, self.env.goal)  # f-cost = g-cost + h-cost\n",
    "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
    "                    came_from[new_state] = current_node.state\n",
    "\n",
    "        return []\n",
    "    \n",
    "    # Performs Uniform Cost Search to find the lowest cost path from the initial state to the goal.\n",
    "    def uniform_cost_search(self):\n",
    "        #self.recharge()\n",
    "        frontier = PriorityQueue()  # Priority queue for UCS.\n",
    "        frontier.put(Node(self.env.initial, path_cost=0), 0)\n",
    "        came_from = {self.env.initial: None}\n",
    "        cost_so_far = {self.env.initial: 0}\n",
    "\n",
    "        while not frontier.empty():\n",
    "            current_node = frontier.get()\n",
    "\n",
    "            if self.env.is_goal(current_node.state):\n",
    "                return self.reconstruct_path(came_from, current_node.state)\n",
    "\n",
    "            for action in self.env.actions(current_node.state):\n",
    "                new_state = self.env.result(current_node.state, action)\n",
    "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity; adjust if varying costs.\n",
    "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
    "                    cost_so_far[new_state] = new_cost\n",
    "                    priority = new_cost\n",
    "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
    "                    came_from[new_state] = current_node.state\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Reconstructs the path from start to goal by following the came_from links.\n",
    "    def reconstruct_path(self, came_from, current):\n",
    "        path = []\n",
    "        #charge = []\n",
    "        while current in came_from:\n",
    "            path.append(current)\n",
    "            current = came_from[current]\n",
    "\n",
    "        path.append(self.env.initial)  # Start is not included in the came_from map.\n",
    "        path.reverse()  # Reverse to get the path from start to goal.\n",
    "        return path           \n",
    "    \n",
    "    # Battery Charging point and management\n",
    "    def battery_manager(self, path):\n",
    "        self.recharge()\n",
    "        charge = []\n",
    "\n",
    "        for i in range(len(path)):\n",
    "            if self.current_charge() <= 10:\n",
    "                charge.append(path[i])\n",
    "                self.recharge()\n",
    "                pass\n",
    "            elif path[i] != (0, 0):\n",
    "                self.battery = self.current_charge() - 10\n",
    "                pass\n",
    "            print(f\"{path[i]} = {self.current_charge()}\")\n",
    "                \n",
    "                \n",
    "        return charge \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Function plots the grid and the found path.\n",
    "def visualize_grid_and_path(grid, path, charge):\n",
    "    grid_array = np.array(grid)  # Convert grid to numpy array for easy plotting.\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(grid_array, cmap='Greys', alpha=0.3)  # Grid background.\n",
    "    start = path[0]\n",
    "    goal = path[-1]\n",
    "    ax.plot(goal[1], goal[0], 'bs', markersize=10)  # goal position in blue.\n",
    "    ax.plot(start[1], start[0], 'ks', markersize=10)  # start position in black.\n",
    "    if (charge is not None) :\n",
    "        xc, yc = zip(*charge) \n",
    "        ax.plot(yc, xc, 'gs', markersize=10)# charging position are in green.\n",
    "     \n",
    "    xs, ys = zip(*path)  # Extract X and Y coordinates of the path.\n",
    "    ax.plot(ys, xs, 'r-', linewidth=2)  # Plot the path in red.\n",
    "    ax.set_xticks(np.arange(-.5, len(grid[0]), 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, len(grid), 1), minor=True)\n",
    "    \n",
    "    ax.grid(which=\"minor\", color=\"b\", linestyle='-', linewidth=1)\n",
    "    ax.tick_params(which=\"minor\", size=0)\n",
    "    ax.tick_params(which=\"major\", bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "driver code. \n",
    "\n",
    "<h3>output serial</h3>\n",
    "<hr>\n",
    "1st --> UFS<br>\n",
    "2nd --> A Star "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the solution using Uniform Cost Search algorithm\n",
      "(0, 0) = 100\n",
      "(0, 0) = 100\n",
      "(1, 0) = 90\n",
      "(2, 0) = 80\n",
      "(3, 0) = 70\n",
      "(4, 0) = 60\n",
      "(5, 0) = 50\n",
      "(5, 1) = 40\n",
      "(6, 1) = 30\n",
      "(6, 2) = 20\n",
      "(6, 3) = 10\n",
      "(6, 4) = 100\n",
      "(6, 5) = 90\n",
      "(6, 6) = 80\n",
      "(6, 7) = 70\n",
      "(7, 7) = 60\n",
      "(8, 7) = 50\n",
      "(8, 8) = 40\n",
      "(8, 9) = 30\n",
      "(9, 9) = 20\n",
      "Charging Points: [(6, 4)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the solution using A* Search algorithm\n",
      "(0, 0) = 100\n",
      "(0, 0) = 100\n",
      "(1, 0) = 90\n",
      "(2, 0) = 80\n",
      "(3, 0) = 70\n",
      "(4, 0) = 60\n",
      "(5, 0) = 50\n",
      "(5, 1) = 40\n",
      "(6, 1) = 30\n",
      "(6, 2) = 20\n",
      "(6, 3) = 10\n",
      "(6, 4) = 100\n",
      "(6, 5) = 90\n",
      "(7, 5) = 80\n",
      "(7, 6) = 70\n",
      "(7, 7) = 60\n",
      "(8, 7) = 50\n",
      "(8, 8) = 40\n",
      "(8, 9) = 30\n",
      "(9, 9) = 20\n",
      "Charging Points: [(6, 4)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_random_grid(size, obstacle_probability):\n",
    "    return np.random.choice([0, 1], size=(size, size), p=[1-obstacle_probability, obstacle_probability])\n",
    "\n",
    "# Define the size of the grid and the probability of an obstacle in each cell\n",
    "grid_size = 10\n",
    "obstacle_probability = 0.2  # 20% chance of being an obstacle\n",
    "\n",
    "# Generate a random grid\n",
    "grid = generate_random_grid(grid_size, obstacle_probability)\n",
    "\n",
    "# Define start and goal positions\n",
    "start = (0, 0)\n",
    "goal = (grid_size - 1, grid_size - 1)\n",
    "\n",
    "# Ensure start and goal are not obstacles\n",
    "grid[start] = 0\n",
    "grid[goal] = 0\n",
    "\n",
    "# Create the environment and agent\n",
    "environment = Environment(grid, start, goal)\n",
    "agent = Agent(environment)\n",
    "\n",
    "# Solve the problem with the UCS algorithm\n",
    "print(\"This is the solution using Uniform Cost Search algorithm\")\n",
    "solution_path_ucs = agent.uniform_cost_search()\n",
    "charging_point = agent.battery_manager(solution_path_ucs)\n",
    "#print(\"Solution Path:\", solution_path_ucs)\n",
    "print(\"Charging Points:\", charging_point)\n",
    "\n",
    "# Visualize the solution\n",
    "visualize_grid_and_path(grid, solution_path_ucs, charging_point) \n",
    "\n",
    "# Solve the problem with the A* algorithm\n",
    "print(\"This is the solution using A* Search algorithm\")\n",
    "solution_path_a_star = agent.a_star_search()\n",
    "charging_point = agent.battery_manager(solution_path_a_star)\n",
    "#print(\"Solution Path:\", solution_path_a_star)\n",
    "print(\"Charging Points:\", charging_point)\n",
    "\n",
    "# Visualize the solution\n",
    "visualize_grid_and_path(grid, solution_path_a_star, charging_point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
